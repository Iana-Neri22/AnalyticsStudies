{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iana-Neri22/AnalyticsStudies/blob/master/analise_covid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 582,
      "metadata": {
        "id": "PnndQNo_3VKO"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 264. MiB for an array with shape (30, 1151956) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[582], line 123\u001b[0m\n\u001b[0;32m    121\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaminho_arquivos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/DadosCovidCompilados.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, usecols\u001b[38;5;241m=\u001b[39mlista_colunas)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcaminho_arquivos\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/DadosCovidCompilados.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlista_colunas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m#else:\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m#    df = pd.concat((pd.read_csv(f) for f in dados_por_mes), ignore_index=True)\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m#    df.to_csv(f'{caminho_arquivos}/DadosCovidCompilados.csv') \u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m#    df = pd.read_csv(f'{caminho_arquivos}/DadosCovidCompilados.csv', usecols=lista_colunas)\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2142\u001b[0m     raise_construction_error(\u001b[38;5;28mlen\u001b[39m(arrays), arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, axes, e)\n\u001b[0;32m   2143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consolidate:\n\u001b[1;32m-> 2144\u001b[0m     \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mgr\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1788\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2267\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2269\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2272\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:2294\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2287\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2292\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2293\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2294\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2296\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 264. MiB for an array with shape (30, 1151956) and data type float64"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from math import nan\n",
        "\n",
        "dict_colunas = {\n",
        "    'UF': 'UF',\n",
        "    'A002': 'Idade', \n",
        "    'A003': 'Gênero', \n",
        "    'A005': 'Escolaridade',\n",
        "    'B0011': 'Sintoma_Febre', \n",
        "    'B0012': 'Sintoma_Tosse',\n",
        "    'B0013': 'Sintoma_Dor_Garganta',\n",
        "    'B0014': 'Sintoma_Dificuldade_Respirar',\n",
        "    'B0015': 'Sintoma_Dor_Cabeca',\n",
        "    'B0016': 'Sintoma_Dor_Peito',\n",
        "    'B0017': 'Sintoma_Nausea',\n",
        "    'B0018': 'Sintoma_Nariz_Entupido',\n",
        "    'B0019': 'Sintoma_Fadiga',\n",
        "    'B00110': 'Sintoma_Dor_Olhos',\n",
        "    'B00111': 'Sintoma_Perda_Cheiro_Sabor', \n",
        "    'B00112': 'Sintoma_Dor_Muscular', \n",
        "    'B0018': 'Sintoma_Nariz_Entupido', \n",
        "    'B0019': 'Sintoma_Fadiga',\n",
        "    'B00110': 'Sintoma_Dor_Olhos',\n",
        "    'B002': 'Buscou_Estabelecimento_Saude',\n",
        "    'B0031': 'Ficou_Casa', \n",
        "    'B0032': 'Ligar_Profissional_Saude', \n",
        "    'B0033': 'Remedio_Conta_Propria',\n",
        "    'B0034': 'Remedio_Orientacao_Medica', \n",
        "    'B0035': 'Visita_Profissional_SUS', \n",
        "    'B0036': 'Visita_Profissional_Particular',\n",
        "    'B0037': 'Outra_Medida_Recuperacao', \n",
        "    'B0042': 'Atendimento_PS_SUS_UPA', \n",
        "    'B0043': 'Atendimento_Hospital_SUS',\n",
        "    'B0044': 'Atendimento_Ambulatorio_Consultorio_Privado_Forcas_Armadas', \n",
        "    'B0045': 'PS_Privado_Forcas_Armadas', \n",
        "    'B0046': 'Hospital_Privado_Forcas_Armadas',\n",
        "    'B005': 'Internacao', \n",
        "    'B006': 'Internacao_Respiracao_Artifical', \n",
        "    'B007': 'Possui_Plano_Saude',\n",
        "    'C001': 'Trabalhou', \n",
        "    'C002': 'Afastado', \n",
        "    'C003': 'Motivo_Afastamento',\n",
        "    'C004': 'Continuou_Remunerado',\n",
        "    'C005': 'Tempo_Afastamento', \n",
        "    'C006': 'Tem_Mais_Um_Trabalho',\n",
        "    'C007': 'Tipo_Emprego', \n",
        "    'C007A': 'Area_Trabalho', \n",
        "    'C007B': 'Tipo_Vinculo_Empregaticio',\n",
        "    'C007C': 'Cargo_Trabalho', \n",
        "    'C007D': 'Atividade_Trabalho', \n",
        "    'C007E': 'Numero_Funcionarios_Empresa',\n",
        "    'C008': 'Horas_Trabalho_Semana', \n",
        "    'C011A11': 'Faixa_Rendimento', \n",
        "    'C013': 'Home_Office',\n",
        "    'V1013': 'Mes_Pesquisa'\n",
        "}\n",
        "\n",
        "dict_uf = {\n",
        "    11: 'RO',\n",
        "    12:\t'AC',\n",
        "    13: 'AM',\n",
        "    14: 'RR',\n",
        "    15:\t'PA',\n",
        "    16: 'AP',\n",
        "    17: 'TO',\n",
        "    21: 'MA',\n",
        "    22:\t'PI',\n",
        "    23: 'CE',\n",
        "    24:\t'RN',\n",
        "    25: 'PB',\n",
        "    26: 'PE',\n",
        "    27: 'AL',\n",
        "    28:\t'SE',\n",
        "    29:\t'BA',\n",
        "    31:\t'MG',\n",
        "    32:\t'ES',\n",
        "    33:\t'RJ',\n",
        "    35:\t'SP',\n",
        "    41:\t'PR',\n",
        "    42:\t'SC',\n",
        "    43:\t'RS',\n",
        "    50:\t'MS',\n",
        "    51:\t'MT',\n",
        "    52:\t'GO',\n",
        "    53:\t'DF'\n",
        "}\n",
        "\n",
        "dict_mes = {\n",
        "    1: 'Janeiro',\n",
        "    2: 'Fevereiro',\n",
        "    3: 'Março',\n",
        "    4: 'Abril',\n",
        "    5: 'Maio',\n",
        "    6: 'Junho',\n",
        "    7: 'Julho',\n",
        "    8: 'Agosto',\n",
        "    9: 'Setembro',\n",
        "    10: 'Outubro',\n",
        "    11: 'Novembro',\n",
        "    12: 'Dezembro'\n",
        "}\n",
        "\n",
        "lista_colunas = list(dict_colunas.keys())\n",
        "\n",
        "# Path de todos os arquivos csv para análise\n",
        "caminho_arquivos = './Datasets'\n",
        "# Armazenando o path de cada arquivo\n",
        "\n",
        "dados_por_mes = glob.glob(os.path.join(caminho_arquivos, \"PNAD_COVID*\"))\n",
        "\n",
        "meu_arquivo = Path(f'{caminho_arquivos}/DadosCovidCompilados.csv')\n",
        "if not meu_arquivo.is_file():\n",
        "    # Unindo todos os arquivos em um único dataframe\n",
        "    df = pd.concat((pd.read_csv(f) for f in dados_por_mes), ignore_index=True)\n",
        "    df.to_csv(f'{caminho_arquivos}/DadosCovidCompilados.csv') \n",
        "    df = pd.read_csv(f'{caminho_arquivos}/DadosCovidCompilados.csv', usecols=lista_colunas)\n",
        "else:\n",
        "    df = pd.read_csv(f'{caminho_arquivos}/DadosCovidCompilados.csv', usecols=lista_colunas)\n",
        "#else:\n",
        "#    df = pd.concat((pd.read_csv(f) for f in dados_por_mes), ignore_index=True)\n",
        "#    df.to_csv(f'{caminho_arquivos}/DadosCovidCompilados.csv') \n",
        "#    df = pd.read_csv(f'{caminho_arquivos}/DadosCovidCompilados.csv', usecols=lista_colunas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BBXwRCif7dMB",
        "outputId": "b158188e-1768-4752-ec9c-9de7028670e9"
      },
      "outputs": [],
      "source": [
        "# Renomeando as colunas do Dataframe para maior legibilidade\n",
        "df = df.rename(columns=dict_colunas)\n",
        "\n",
        "# Substituindo o código de UF pela sigla dos estados\n",
        "df = df.replace({\"UF\": dict_uf})\n",
        "\n",
        "# Exibir as 5 primeiras linhas do Dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exibir o número total de linhas e colunas do dataframe\n",
        "print(f'Nº de Linhas: {df.shape[0]}')\n",
        "print(f'Nº de Colunas: {df.shape[1]}')\n",
        "\n",
        "#Tipo das variáveis\n",
        "#df.dtypes.sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Verificando valores ausentes do df (isnull().sum())\n",
        "(df.isnull().sum()/df.shape[0]).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valores correspondentes ao mês de início e fim da pesquisa\n",
        "print('Início: ', df.Mes_Pesquisa.min())\n",
        "print('Fim: ', df.Mes_Pesquisa.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Resumo do dataset com as colunas e o tipo de dados presente em cada uma delas\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar os estados presentes na pesquisa\n",
        "print(f'Os estados presente na pesquisa são: {df[\"UF\"].unique()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tratamento para exibir o número de Entrevistados em cada mês e o total de pessoas entrevistadas na pesquisa\n",
        "# Primeiro estou agrupando o dataframe pelo mês da pesquisa e somando o valor de pessoas entrevista a cada mês\n",
        "# Também renomeio as colunas para tornar o Dataframe mais legível\n",
        "\n",
        "tot_entrevistados = df.groupby(['Mes_Pesquisa'])['UF'].count()\n",
        "tot_entrevistados = pd.DataFrame({'Mês': tot_entrevistados.index, 'Entrevistados':tot_entrevistados.values})\n",
        "tot_entrevistados = tot_entrevistados.replace({\"Mês\": dict_mes})\n",
        "total = tot_entrevistados['Entrevistados'].sum()\n",
        "tot_entrevistados.loc[-1] = ['Total', total]\n",
        "tot_entrevistados.index = tot_entrevistados.index + 1\n",
        "\n",
        "display(tot_entrevistados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Total de UF presentes na pesquisa \n",
        "\n",
        "print(f'Ao total {len(df[\"UF\"].unique())} UFs participaram da pesquisa.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quais estados tiveram o maior número de entrevistados?\n",
        "\n",
        "# Agrupo os dados por UF e conto o total de participantes em cada estado\n",
        "# Ordeno os dados primeiro pelo número total de entrevistados e depois pela UF \n",
        "\n",
        "df_entrev_uf = df.groupby(['UF'])['UF'].count()\n",
        "df_entrev_uf = pd.DataFrame({'UF': df_entrev_uf.index, 'Total de Entrevistados':df_entrev_uf.values})\n",
        "df_entrev_uf = df_entrev_uf.sort_values(by=['Total de Entrevistados', 'UF'], ascending=[False, True])\n",
        "df_entrev_uf['País'] = 'BRA'\n",
        "display(df_entrev_uf)\n",
        "\n",
        "df_entrev_uf.to_csv(f'{caminho_arquivos}/entrevistados_uf.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfico para exibir o número total de entrevistados por UF\n",
        "df_entrev_uf.plot(x=\"UF\", y=\"Total de Entrevistados\", kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_respostas = {\n",
        "1: 'Sim',\n",
        "2: 'Não', \n",
        "3: 'Não sabe',\n",
        "9: 'Ignorado'\n",
        "}\n",
        "\n",
        "# Exibir a frequência dos sintomas que os entrevistados mais tiveram semana passada\n",
        "lista_sintomas = [i for i in list(dict_colunas.values()) if i.startswith('Sintoma')]\n",
        "df_sintomas = df[lista_sintomas]\n",
        "df_sintomas['UF'] = df['UF']\n",
        "df_sintomas[lista_sintomas] = df_sintomas[lista_sintomas].apply(lambda x: (x == 1).astype(int))\n",
        "df_sint_grouped = df_sintomas.groupby('UF').sum().reset_index()\n",
        "\n",
        "if not os.path.exists(f'{caminho_arquivos}/sintomas_uf.csv'):\n",
        "    df_sint_grouped.to_csv(f'{caminho_arquivos}/sintomas_uf.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ = df[df['Trabalhou'].isin([1, 2])]\n",
        "cols_sintomas = [i for i in list(dict_colunas.values()) if i.startswith('Sintoma')]\n",
        "df['Total_Sintomas'] = (df[cols_sintomas] == 1).sum(axis=1)\n",
        "bins = [0, 18, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "labels = ['0-18', '19-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
        "df['Faixa_Etaria'] = pd.cut(df['Idade'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Contar o número de indivíduos por faixa etária e sexo\n",
        "df_piramide = df.groupby(['Faixa_Etaria', 'Gênero']).size().unstack(fill_value=0)\n",
        "\n",
        "# Para gráfico de pirâmide populacional, você pode querer ajustar os valores para que os homens e mulheres apareçam em lados opostos\n",
        "df_piramide = df_piramide.reset_index()\n",
        "\n",
        "#df_2 = df_piramide.melt(id_vars='Total_Sintomas', var_name='Gênero', value_name='Total de sintomas por gênero')\n",
        "#display(df_2)\n",
        "#\n",
        "df_piramide = df_piramide.melt(id_vars='Faixa_Etaria', var_name='Gênero', value_name='Total por Gênero e Faixa Etária')\n",
        "df_piramide['Gênero'] = df_piramide['Gênero'].map({1: 'Masculino', 2: 'Feminino'})\n",
        "\n",
        "# Exportar o DataFrame para um arquivo CSV se necessário\n",
        "df_piramide.to_csv(f'{caminho_arquivos}/piramide_populacional.csv', index=False)\n",
        "display(df_piramide)\n",
        "#df_pie = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict_genero = {\n",
        "    1: 'Masculino',\n",
        "    2: 'Feminino'\n",
        "}\n",
        "\n",
        "# Listar colunas de sintomas\n",
        "cols_sintomas = [i for i in dict_colunas.values() if i.startswith('Sintoma')]\n",
        "\n",
        "# Calcular total de sintomas\n",
        "df['Total_Sintomas'] = (df[cols_sintomas] == 1).sum(axis=1)\n",
        "\n",
        "# Criar faixa etária\n",
        "bins = [0, 18, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "labels = ['0-18', '19-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
        "df['Faixa_Etaria'] = pd.cut(df['Idade'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Substituir valores de gênero com dict_genero\n",
        "df['Gênero'] = df['Gênero'].map(dict_genero)\n",
        "\n",
        "# Contar o número de indivíduos por faixa etária e sexo\n",
        "df_piramide = df.groupby(['Faixa_Etaria', 'Gênero']).size().unstack(fill_value=0)\n",
        "df_piramide = df_piramide.apply(lambda x: x if x.name == 'Masculino' else -x, axis=1).reset_index()\n",
        "\n",
        "# Agrupar total de sintomas por gênero\n",
        "df_pie = df.groupby('Gênero')['Total_Sintomas'].sum().reset_index()\n",
        "df_pie['Porcentagem'] = df_pie['Total_Sintomas'] / df_pie['Total_Sintomas'].sum() * 100\n",
        "\n",
        "\n",
        "display(df_piramide)\n",
        "# Gráfico de pirâmide populacional\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_piramide.plot(kind='barh', x='Faixa_Etaria', stacked=True, color=['blue', 'red'], ax=plt.gca())\n",
        "plt.title('Pirâmide Populacional por Gênero e Faixa Etária')\n",
        "plt.xlabel('Número de Indivíduos')\n",
        "plt.ylabel('Faixa Etária')\n",
        "plt.legend(title='Gênero')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Gráfico de pizza\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(df_pie['Porcentagem'], labels=df_pie['Gênero'], autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])\n",
        "plt.title('Total de Sintomas por Gênero')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df['Home_Office'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mapeando valores na coluna 'Trabalhou'\n",
        "df['Trabalhou'] = df['Trabalhou'].map({1: 'Sim', 2: 'Não', np.nan: 'Vazio'})\n",
        "df['Home_Office'] = df['Home_Office'].map({1: 'Sim', 2: 'Não', np.nan: 'Vazio'})\n",
        "#print(df['Trabalhou'].unique())\n",
        "\n",
        "# Mapeando valores na coluna 'Home_Office'\n",
        "#df['Home_Office'] = df['Home_Office'].map({1: 'Sim', 2: 'Não', np.nan: 'Não Informado'})\n",
        "#print(df['Home_Office'].unique())\n",
        "\n",
        "# Filtrar apenas os indivíduos que trabalharam\n",
        "df_trabalhou = df[df['Trabalhou'] == 'Sim']\n",
        "df_trabalhou = df_trabalhou[df_trabalhou['Home_Office'].isin(['Sim', 'Não'])]\n",
        "\n",
        "# Filtrar onde a coluna 'Home_Office' tem os valores 'Sim' ou 'Não'\n",
        "\n",
        "\n",
        "# Contar os casos de trabalho em home office e não home office, por gênero\n",
        "df_trabalhou_home_office = df_trabalhou.groupby(['Gênero', 'Home_Office']).size().unstack(fill_value=0)\n",
        "#display(df_trabalhou_home_office)\n",
        "# Criar o gráfico de barras empilhadas\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_trabalhou_home_office.plot(kind='bar', stacked=True, color=['lightblue', 'lightcoral'], ax=plt.gca())\n",
        "plt.title('Número de Indivíduos que Trabalharam (Empilhado por Home Office) por Gênero')\n",
        "plt.xlabel('Gênero')\n",
        "plt.ylabel('Número de Indivíduos')\n",
        "plt.legend(title='Home Office')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df['Trabalhou'] = df['Trabalhou'].map({1: 'Sim', 2: 'Não', np.nan: 'Vazio'})\n",
        "#df['Home_Office'] = df['Home_Office'].map({1: 'Sim', 2: 'Não', np.nan: 'Não Informado'})\n",
        "\n",
        "# Filtrar apenas os indivíduos que trabalharam\n",
        "#df_trabalhou = df[df['Trabalhou'] == 'Sim']\n",
        "#df_trabalhou = df\n",
        "#display(df_trabalhou['Trabalhou'])\n",
        "# Filtrar onde a coluna 'Home_Office' tem os valores 'Sim' ou 'Não'\n",
        "\n",
        "#df_trabalhou = df_trabalhou[df_trabalhou['Home_Office'].isin(['Sim', 'Não'])]\n",
        "\n",
        "# Agregar o número total de sintomas por gênero e status de home office\n",
        "df_sintomas = df_trabalhou.groupby(['Gênero', 'Home_Office'])['Total_Sintomas'].sum().unstack(fill_value=0).reset_index()\n",
        "display(df_sintomas)\n",
        "# Calcular a porcentagem de sintomas por gênero e status de home office\n",
        "\n",
        "df_sintomas.set_index('Gênero', inplace=True)\n",
        "df_sintomas_percentage = df_sintomas.div(df_sintomas.sum(axis=1), axis=0) * 100\n",
        "\n",
        "\n",
        "# Criar o gráfico de colunas empilhadas\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = df_sintomas_percentage.plot(kind='bar', stacked=True, colormap='viridis', figsize=(10, 6))\n",
        "\n",
        "plt.title('Porcentagem de Total de Sintomas por Trabalho em Home Office e Gênero')\n",
        "plt.xlabel('Gênero')\n",
        "plt.ylabel('Porcentagem de Total de Sintomas')\n",
        "plt.legend(title='Home Office')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sintomas = df_trabalhou.groupby(['Gênero', 'Home_Office'])['Total_Sintomas'].sum().unstack(fill_value=0).reset_index()\n",
        "\n",
        "# Criar gráfico de rosca para cada gênero\n",
        "for genero in df_sintomas['Gênero']:\n",
        "    subset = df_sintomas[df_sintomas['Gênero'] == genero]\n",
        "    total_sintomas = subset.drop(columns='Gênero').sum(axis=1).values[0]\n",
        "    sintomas_percentuais = (subset.drop(columns='Gênero').div(total_sintomas, axis=0).values[0] * 100)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.pie(sintomas_percentuais, labels=subset.columns[1:], autopct='%1.1f%%', startangle=140, \n",
        "            wedgeprops=dict(width=0.3), colors=['lightblue', 'lightcoral'])\n",
        "    plt.title(f'Distribuição Percentual de Sintomas por Home Office - {genero}')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONcnQeAZ4c403Y3JjnTsCy",
      "include_colab_link": true,
      "mount_file_id": "17nIyW2bZbSSf3HLcH5kM47CA0uu2qJGn",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
